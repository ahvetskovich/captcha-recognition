/usr/bin/python3.4 /home/andy/Github/captcha-recognition/PyProj/ML/securimage/convolution.py
Initializing neural network with 2 layers, 1936 inputs and 29 outputs.
  - Convl: Rectifier  Output: (23, 23)   Channels: 8
  - Dense: Softmax    Units:  29  

Training on dataset of 3,500 samples with 6,877,500 total size.
  - Reshaping input array from (3500, 1936) to (3150, 1, 44, 44).
  - Train: 3,150      Valid: 350 
  - Using `dropout` for regularization.
  - Terminating loop after 100 total iterations.
  - Early termination after 10 stable iterations.

Epoch       Training Error       Validation Error       Time
------------------------------------------------------------
    1          7.605e+01             3.328e+01          2.1s
    2          2.803e+01             1.570e+01          2.1s
    3          1.738e+01             1.149e+01          2.1s
    4          1.283e+01             9.694e+00          2.1s
    5          1.054e+01             9.302e+00          2.1s
    6          9.137e+00             7.300e+00          2.1s
    7          8.207e+00             6.844e+00          2.1s
    8          7.458e+00             6.632e+00          2.1s
    9          6.578e+00             6.384e+00          2.1s
   10          6.672e+00             5.893e+00          2.1s
   11          5.835e+00             5.695e+00          2.1s
   12          5.504e+00             5.834e+00          2.1s
   13          5.364e+00             5.314e+00          2.1s
   14          4.928e+00             5.748e+00          2.1s
   15          4.796e+00             5.308e+00          2.1s
   16          4.706e+00             5.073e+00          2.1s
   17          4.482e+00             5.254e+00          2.1s
   18          4.196e+00             4.921e+00          2.1s
   19          4.118e+00             4.819e+00          2.1s
   20          3.759e+00             5.075e+00          2.1s
   21          3.846e+00             4.612e+00          2.1s
   22          3.798e+00             5.306e+00          2.1s
   23          3.695e+00             4.824e+00          2.1s
   24          3.351e+00             4.515e+00          2.1s
   25          3.372e+00             4.761e+00          2.1s
   26          3.453e+00             4.467e+00          2.1s
   27          3.331e+00             4.526e+00          2.1s
   28          3.341e+00             4.522e+00          2.1s
   29          2.928e+00             4.509e+00          2.1s
   30          2.964e+00             4.484e+00          2.1s
   31          2.883e+00             4.275e+00          2.1s
   32          2.880e+00             4.380e+00          2.1s
   33          2.820e+00             4.223e+00          2.1s
   34          2.696e+00             4.202e+00          2.1s
   35          2.643e+00             4.145e+00          2.1s
   36          2.515e+00             4.337e+00          2.1s
   37          2.489e+00             4.316e+00          2.1s
   38          2.441e+00             4.071e+00          2.1s
   39          2.517e+00             4.060e+00          2.1s
   40          2.342e+00             4.070e+00          2.1s
   41          2.296e+00             3.934e+00          2.2s
   42          2.095e+00             3.930e+00          2.1s
   43          2.161e+00             4.053e+00          2.1s
   44          2.247e+00             4.124e+00          2.1s
   45          1.978e+00             3.993e+00          2.1s
   46          1.943e+00             4.119e+00          2.1s
   47          2.035e+00             4.027e+00          2.2s
   48          2.079e+00             4.302e+00          2.1s
   49          1.967e+00             4.228e+00          2.1s
   50          1.649e+00             4.041e+00          2.1s
   51          1.835e+00             4.173e+00          2.2s
   52          1.958e+00             4.016e+00          2.2s

Early termination condition fired at 52 iterations.
Classification report for classifier Classifier(batch_size=10, callback=None, debug=False, dropout_rate=0.03,
      f_stable=0.001,
      hidden0=<sknn.nn.Convolution `Rectifier`: channels=8, pool_shape=(2, 2), scale_factor=(1, 1), pool_type='max', name='hidden0', frozen=False, border_mode='full', kernel_shape=(3, 3), kernel_stride=(1, 1)>,
      layers=[<sknn.nn.Convolution `Rectifier`: channels=8, pool_shape=(2, 2), scale_factor=(1, 1), pool_type='max', name='hidden0', frozen=False, border_mode='full', kernel_shape=(3, 3), kernel_stride=(1, 1)>, <sknn.nn.Layer `Softmax`: frozen=False, name='output', units=29>],
      learning_momentum=0.9, learning_rate=3e-07, learning_rule='momentum',
      loss_type=None, n_iter=100, n_stable=10,
      output=<sknn.nn.Layer `Softmax`: frozen=False, name='output', units=29>,
      random_state=None, regularize='dropout',
      valid_set=(array([[[[ 0,  0, ...,  0,  0],
         [ 0,  0, ...,  0,  0],
         ...,
         [ 0,  0, ...,  0,  0],
         [ 0,  0, ...,  0,  0]]],


       [[[ 0,  0, ...,  0,  0],
         [ 0,  0, ...,  0,  0],
         ...,
         [ 0,  0, ...,  0,  0],
         [ 0,  0, ...,  0,  0]]..., ...,  0.,  0.],
       ...,
       [ 0.,  0., ...,  0.,  0.],
       [ 0.,  0., ...,  0.,  0.]])),
      valid_size=0.1, verbose=True, warning=None, weight_decay=0.0005,
      weights=None):
             precision    recall  f1-score   support

          2     0.9259    0.8621    0.8929        58
          3     0.9767    0.8750    0.9231        48
          4     0.9831    1.0000    0.9915        58
          5     0.8864    0.8298    0.8571        47
          6     0.8478    0.8864    0.8667        44
          7     0.9808    0.9444    0.9623        54
          8     0.7941    0.7714    0.7826        35
          9     0.8448    0.9608    0.8991        51
          a     1.0000    0.9608    0.9800        51
          b     0.7931    0.8846    0.8364        52
          c     0.9583    0.8846    0.9200        52
          d     0.9400    0.8246    0.8785        57
          e     0.9400    0.8545    0.8952        55
          f     0.8800    0.9362    0.9072        47
          g     0.7288    0.8600    0.7890        50
          h     0.9492    0.9333    0.9412        60
          k     0.8780    0.9730    0.9231        37
          l     0.9516    1.0000    0.9752        59
          m     0.9091    0.9302    0.9195        43
          n     0.9245    0.9074    0.9159        54
          p     0.9111    0.9318    0.9213        44
          r     0.9825    0.9032    0.9412        62
          s     0.8718    0.8500    0.8608        40
          t     0.8824    0.9677    0.9231        62
          u     0.9615    0.9434    0.9524        53
          v     0.9796    0.9600    0.9697        50
          w     1.0000    0.9200    0.9583        50
          y     1.0000    0.9524    0.9756        63
          z     0.9014    1.0000    0.9481        64

avg / total     0.9209    0.9173    0.9178      1500


Confusion matrix:
[[50  0  0  0  0  0  0  1  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  5]
 [ 2 42  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1
   0  0  0  0  0]
 [ 0  0 58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0 39  2  0  1  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  2
   1  0  0  0  0]
 [ 0  0  0  1 39  0  0  1  0  1  0  0  0  1  1  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2
   0  0  0  0  1]
 [ 0  1  0  0  2  0 27  0  0  1  0  0  1  1  1  0  0  0  0  0  0  0  1  0
   0  0  0  0  0]
 [ 1  0  0  0  1  0  0 49  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 49  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  3  0  0 46  0  1  0  0  0  0  0  0  1  0  0  1  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 46  0  0  0  6  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  1  0  0  0 47  0  1  8  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  1  0  0  0  0  0  1  1  0 47  1  0  0  0  2  0  0  1  0  1  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  1  0  0  0 44  0  0  0  0  0  0  1  0  0  0
   0  0  0  0  1]
 [ 1  0  0  0  2  0  0  1  0  0  1  0  0  0 43  0  0  0  0  0  0  0  2  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 56  0  0  0  3  0  0  0  1
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 36  1  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 59  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0 40  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0  1 49  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0 41  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  1  0  2  0  0  0  0  0  1  0  0  0  0  2 56  0  0
   0  0  0  0  0]
 [ 0  0  0  2  0  0  1  1  0  1  0  1  0  0  0  0  0  0  0  0  0  0 34  0
   0  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 60
   0  0  0  0  0]
 [ 0  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0
  50  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0
   1 48  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  1  1  0  0  0  0
   0  0 46  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2
   0  1  0 60  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0 64]]

Process finished with exit code 0


/usr/bin/python3.4 /home/andy/Github/captcha-recognition/PyProj/ML/securimage/convolution.py
Initializing neural network with 2 layers, 1936 inputs and 29 outputs.
  - Convl: Rectifier  Output: (23, 23)   Channels: 8
  - Dense: Softmax    Units:  29  

Training on dataset of 3,500 samples with 6,877,500 total size.
  - Reshaping input array from (3500, 1936) to (3150, 1, 44, 44).
  - Train: 3,150      Valid: 350 
  - Using `dropout` for regularization.
  - Terminating loop after 100 total iterations.
  - Early termination after 10 stable iterations.

Epoch       Training Error       Validation Error       Time
------------------------------------------------------------
    1          1.974e+01             4.626e+00          4.7s
    2          6.360e+00             3.001e+00          4.8s
    3          4.526e+00             3.220e+00          4.8s
    4          3.402e+00             2.213e+00          4.8s
    5          2.655e+00             2.210e+00          4.8s
    6          2.137e+00             2.027e+00          4.8s
    7          2.054e+00             1.951e+00          5.0s
    8          1.597e+00             1.894e+00          4.9s
    9          1.611e+00             1.696e+00          5.1s
   10          1.192e+00             1.764e+00          4.7s
   11          1.057e+00             1.871e+00          4.7s
   12          9.117e-01             1.832e+00          4.7s
   13          9.562e-01             1.902e+00          4.7s
   14          8.490e-01             1.782e+00          4.7s
   15          8.373e-01             1.672e+00          4.7s
   16          6.543e-01             1.733e+00          4.7s
   17          6.112e-01             1.954e+00          4.7s
   18          6.383e-01             1.979e+00          4.8s
   19          5.214e-01             1.874e+00          4.7s
   20          5.302e-01             1.581e+00          4.7s
   21          5.476e-01             1.872e+00          4.7s
   22          4.086e-01             1.653e+00          4.7s
   23          4.332e-01             1.749e+00          4.7s
   24          4.445e-01             1.656e+00          4.7s
   25          3.145e-01             1.635e+00          4.7s
   26          3.255e-01             1.686e+00          4.7s
   27          2.982e-01             1.468e+00          4.7s
   28          3.166e-01             1.574e+00          4.7s
   29          2.601e-01             1.594e+00          4.7s
   30          2.442e-01             1.657e+00          4.7s
   31          4.107e-01             1.498e+00          4.7s
   32          2.503e-01             1.518e+00          4.9s
   33          2.319e-01             1.396e+00          4.8s
   34          1.957e-01             1.641e+00          4.8s
   35          2.089e-01             1.678e+00          4.7s
   36          2.512e-01             1.379e+00          4.9s
   37          2.175e-01             1.476e+00          4.9s
   38          2.079e-01             1.566e+00          5.0s
   39          1.885e-01             1.463e+00          5.6s
   40          1.410e-01             1.580e+00          4.9s
   41          2.026e-01             1.512e+00          5.0s
   42          1.551e-01             1.375e+00          5.1s
   43          1.884e-01             1.638e+00          4.9s
   44          1.868e-01             1.519e+00          4.9s
   45          1.621e-01             1.541e+00          4.8s
   46          1.073e-01             1.455e+00          5.1s
   47          1.027e-01             1.611e+00          5.0s
   48          1.366e-01             1.601e+00          5.0s
   49          1.334e-01             1.696e+00          4.9s
   50          1.170e-01             1.571e+00          4.8s
   51          9.326e-02             1.514e+00          4.8s
   52          1.192e-01             1.607e+00          5.0s

Early termination condition fired at 52 iterations.
Classification report for classifier Classifier(batch_size=1, callback=None, debug=False, dropout_rate=0.03,
      f_stable=0.001,
      hidden0=<sknn.nn.Convolution `Rectifier`: name='hidden0', channels=8, frozen=False, scale_factor=(1, 1), kernel_stride=(1, 1), border_mode='full', kernel_shape=(3, 3), pool_shape=(2, 2), pool_type='max'>,
      layers=[<sknn.nn.Convolution `Rectifier`: name='hidden0', channels=8, frozen=False, scale_factor=(1, 1), kernel_stride=(1, 1), border_mode='full', kernel_shape=(3, 3), pool_shape=(2, 2), pool_type='max'>, <sknn.nn.Layer `Softmax`: name='output', units=29, frozen=False>],
      learning_momentum=0.9, learning_rate=5e-07, learning_rule='momentum',
      loss_type=None, n_iter=100, n_stable=10,
      output=<sknn.nn.Layer `Softmax`: name='output', units=29, frozen=False>,
      random_state=None, regularize='dropout',
      valid_set=(array([[[[  0, 124, ...,   0,   0],
         [  0, 124, ...,   0,   0],
         ...,
         [  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0]]],


       [[[  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0],
         ...,
         [  0,   0, ...,   0,   0],
   ..., ...,  0.,  0.],
       ...,
       [ 0.,  0., ...,  0.,  0.],
       [ 0.,  0., ...,  0.,  0.]])),
      valid_size=0.1, verbose=True, warning=None, weight_decay=0.0005,
      weights=None):
             precision    recall  f1-score   support

          2     0.9259    0.9434    0.9346        53
          3     0.9783    0.9000    0.9375        50
          4     1.0000    1.0000    1.0000        47
          5     0.9459    0.8750    0.9091        40
          6     0.8537    0.8750    0.8642        40
          7     0.9130    0.9130    0.9130        46
          8     0.8298    0.8864    0.8571        44
          9     0.9231    0.9600    0.9412        50
          a     0.9808    0.9273    0.9533        55
          b     0.8929    0.8333    0.8621        60
          c     0.9792    0.8704    0.9216        54
          d     0.9000    0.9375    0.9184        48
          e     0.9455    0.8667    0.9043        60
          f     0.9574    0.9184    0.9375        49
          g     0.8214    0.9583    0.8846        48
          h     0.9608    0.9074    0.9333        54
          k     0.9815    0.8833    0.9298        60
          l     0.9322    0.9649    0.9483        57
          m     0.9091    0.9259    0.9174        54
          n     0.7455    0.9762    0.8454        42
          p     0.9000    0.9184    0.9091        49
          r     0.9643    0.9310    0.9474        58
          s     0.9535    0.8913    0.9213        46
          t     0.9667    0.9206    0.9431        63
          u     0.9231    0.9412    0.9320        51
          v     0.9385    0.9531    0.9457        64
          w     0.9565    0.9362    0.9462        47
          y     0.8852    0.9474    0.9153        57
          z     0.8983    0.9815    0.9381        54

avg / total     0.9256    0.9220    0.9225      1500


Confusion matrix:
[[50  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0
   0  0  0  0  0]
 [ 0 45  0  0  1  0  1  0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  1  0
   0  0  0  0  0]
 [ 0  0 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0 35  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   1  0  0  0  1]
 [ 0  0  0  1 35  0  0  0  0  2  0  1  0  0  1  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 1  0  0  0  0 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0
   0  1  0  1  0]
 [ 0  0  0  0  1  0 39  0  0  1  0  0  0  0  1  0  0  0  0  0  1  0  0  0
   0  0  0  0  1]
 [ 0  0  0  0  0  0  1 48  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 51  0  0  0  0  0  1  0  0  0  2  1  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  1  0  4  0  0 50  0  1  1  0  1  0  0  0  0  0  0  0  0  0
   0  0  1  0  1]
 [ 0  0  0  0  1  0  0  0  0  0 47  1  0  0  3  0  0  1  0  0  0  0  0  0
   1  0  0  0  0]
 [ 0  1  0  0  0  0  0  1  0  1  0 45  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 1  0  0  1  0  0  0  0  0  0  1  0 52  1  0  0  0  2  0  0  0  0  0  0
   1  0  0  0  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  1 45  0  0  0  0  0  0  2  0  0  1
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0 46  0  0  0  0  0  0  0  0  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 49  0  0  0  5  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  2 53  0  0  2  0  1  0  0
   0  0  0  0  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 55  0  0  0  0  0  0
   0  0  0  1  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  4  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 41  0  0  0  0
   0  0  1  0  0]
 [ 0  0  0  0  0  0  0  1  0  0  0  1  0  1  0  0  0  0  0  0 45  0  0  0
   0  0  0  1  0]
 [ 0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  2 54  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  1  1  0  0  0  0  0  0  2  0  1  0  0  0  0  0 41  0
   0  0  0  0  0]
 [ 0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58
   0  0  0  1  0]
 [ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0
  48  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0
   0 61  0  2  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0
   0  0 44  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  3  0 54  0]
 [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0 53]]

Process finished with exit code 0

=======================================

/usr/bin/python3.4 /opt/pycharm-community-5.0.3/helpers/pydev/pydevd.py --multiproc --qt-support --client 127.0.0.1 --port 47710 --file /home/andy/Github/captcha-recognition/PyProj/ML/securimage/convolution.py
pydev debugger: process 25786 is connecting

Connected to pydev debugger (build 143.1559)
Initializing neural network with 2 layers, 1936 inputs and 29 outputs.
  - Convl: Rectifier  Output: (42, 42)   Channels: 8
  - Dense: Softmax    Units:  29  

Training on dataset of 3,500 samples with 6,877,500 total size.
  - Reshaping input array from (3500, 1936) to (3150, 1, 44, 44).
  - Train: 3,150      Valid: 350 
  - Using `dropout` for regularization.
  - Terminating loop after 100 total iterations.
  - Early termination after 10 stable iterations.

Epoch       Training Error       Validation Error       Time
------------------------------------------------------------
    1          3.732e+01             9.094e+00         16.2s
    2          1.124e+01             5.331e+00         16.2s
    3          7.283e+00             3.746e+00         16.3s
    4          6.194e+00             3.353e+00         16.2s
    5          5.007e+00             2.663e+00         16.2s
    6          4.402e+00             2.222e+00         16.2s
    7          3.982e+00             2.338e+00         16.2s
    8          3.684e+00             2.005e+00         16.2s
    9          3.215e+00             2.063e+00         16.2s
   10          3.027e+00             1.864e+00         16.2s
   11          2.627e+00             1.607e+00         16.2s
   12          2.546e+00             1.531e+00         16.1s
   13          2.606e+00             1.687e+00         16.3s
   14          2.372e+00             1.572e+00         16.2s
   15          2.327e+00             1.661e+00         16.2s
   16          2.000e+00             1.556e+00         16.2s
   17          2.002e+00             1.506e+00         16.2s
   18          1.905e+00             1.510e+00         16.2s
   19          1.794e+00             1.342e+00         16.1s
   20          1.831e+00             1.288e+00         16.2s
   21          1.786e+00             1.148e+00         16.1s
   22          1.564e+00             1.323e+00         16.2s
   23          1.606e+00             1.254e+00         16.2s
   24          1.557e+00             1.301e+00         16.2s
   25          1.390e+00             1.294e+00         16.3s
   26          1.574e+00             1.197e+00         16.2s
   27          1.392e+00             1.199e+00         16.2s
   28          1.355e+00             1.119e+00         16.2s
   29          1.187e+00             1.088e+00         16.2s
   30          1.235e+00             1.314e+00         16.2s
   31          1.089e+00             1.305e+00         16.3s
   32          1.168e+00             1.169e+00         16.3s
   33          1.104e+00             1.205e+00         16.2s
   34          9.994e-01             1.056e+00         16.3s
   35          1.108e+00             1.136e+00         16.2s
   36          1.005e+00             1.208e+00         16.1s
   37          1.088e+00             1.183e+00         16.2s
   38          8.856e-01             1.044e+00         16.3s
   39          9.082e-01             1.089e+00         16.1s
   40          8.594e-01             1.071e+00         16.2s
   41          8.853e-01             1.084e+00         16.1s
   42          8.784e-01             1.155e+00         16.1s
   43          9.127e-01             1.062e+00         16.2s
   44          8.276e-01             1.053e+00         16.3s
   45          8.172e-01             1.112e+00         16.2s
   46          7.864e-01             1.155e+00         16.3s
   47          8.659e-01             1.063e+00         16.2s
   48          7.890e-01             1.099e+00         16.2s

Early termination condition fired at 48 iterations.
Classification report for classifier Classifier(batch_size=1, callback=None, debug=False, dropout_rate=0.03,
      f_stable=0.001,
      hidden0=<sknn.nn.Convolution `Rectifier`: name='hidden0', kernel_stride=(1, 1), scale_factor=(1, 1), frozen=False, border_mode='valid', pool_shape=(1, 1), kernel_shape=(3, 3), channels=8>,
      layers=[<sknn.nn.Convolution `Rectifier`: name='hidden0', kernel_stride=(1, 1), scale_factor=(1, 1), frozen=False, border_mode='valid', pool_shape=(1, 1), kernel_shape=(3, 3), channels=8>, <sknn.nn.Layer `Softmax`: name='output', frozen=False, units=29>],
      learning_momentum=0.9, learning_rate=3e-08, learning_rule='momentum',
      loss_type=None, n_iter=100, n_stable=10,
      output=<sknn.nn.Layer `Softmax`: name='output', frozen=False, units=29>,
      random_state=None, regularize='dropout',
      valid_set=(array([[[[  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0],
         ...,
         [  0,  75, ..., 218, 194],
         [  0,   0, ...,  98,   0]]],


       [[[255, 255, ...,   0,   0],
         [255, 255, ...,   0,   0],
         ...,
         [  0,   0, ...,   0,   0],
   ..., ...,  0.,  0.],
       ...,
       [ 0.,  0., ...,  0.,  0.],
       [ 0.,  0., ...,  0.,  0.]])),
      valid_size=0.1, verbose=True, warning=None, weight_decay=0.0005,
      weights=None):
             precision    recall  f1-score   support

          2     0.9216    0.9400    0.9307        50
          3     0.9400    0.9792    0.9592        48
          4     1.0000    0.9250    0.9610        40
          5     0.8511    0.9091    0.8791        44
          6     0.7917    0.8261    0.8085        46
          7     0.9245    1.0000    0.9608        49
          8     0.8409    0.8409    0.8409        44
          9     0.8889    0.9796    0.9320        49
          a     0.9423    1.0000    0.9703        49
          b     0.8644    0.7969    0.8293        64
          c     0.9388    0.9200    0.9293        50
          d     0.9811    0.8966    0.9369        58
          e     0.9273    0.8644    0.8947        59
          f     0.9831    1.0000    0.9915        58
          g     0.8868    0.9400    0.9126        50
          h     0.9333    0.8750    0.9032        48
          k     0.9111    0.8913    0.9011        46
          l     1.0000    1.0000    1.0000        59
          m     0.9016    0.9483    0.9244        58
          n     0.8065    0.9434    0.8696        53
          p     0.9714    1.0000    0.9855        34
          r     0.9322    0.9322    0.9322        59
          s     0.9245    0.8750    0.8991        56
          t     0.9677    0.9375    0.9524        64
          u     0.9057    0.9412    0.9231        51
          v     0.9388    0.8846    0.9109        52
          w     1.0000    0.8600    0.9247        50
          y     0.9592    0.9592    0.9592        49
          z     0.9672    0.9365    0.9516        63

avg / total     0.9252    0.9233    0.9233      1500


Confusion matrix:
[[47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0
   0  0  0  0  2]
 [ 0 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   0  0  0  0  0]
 [ 0  0 37  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0
   1  0  0  0  0]
 [ 0  0  0 40  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0
   0  0  0  0  0]
 [ 0  0  0  0 38  0  2  0  0  1  0  0  1  0  0  0  1  0  0  0  0  0  1  0
   1  1  0  0  0]
 [ 0  0  0  0  0 49  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  2  0 37  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  1  0
   0  0  0  0  0]
 [ 0  0  0  1  0  0  0 48  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 49  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 1  1  0  2  3  0  3  1  0 51  0  0  0  0  0  0  0  0  0  0  0  2  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 46  0  1  0  3  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1  0  0  0  0  0  1  0  1  1 52  0  0  2  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 1  0  0  1  1  0  1  0  0  1  2  0 51  0  1  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 58  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1  0  0  1  0  1  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 42  1  0  0  3  0  2  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1 41  0  0  2  0  0  0  1
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 59  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0 55  1  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  2 50  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0  1 55  0  0
   0  0  0  0  0]
 [ 0  0  0  3  0  0  0  2  0  1  0  0  0  0  0  0  0  0  1  0  0  0 49  0
   0  0  0  0  0]
 [ 0  0  0  0  0  2  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 60
   0  0  0  1  0]
 [ 0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  48  1  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0
   2 46  0  0  0]
 [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  2  0  0  0  0
   1  1 43  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0
   0  0  0 47  0]
 [ 2  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0 59]]

Process finished with exit code 0

====================================================
/usr/bin/python3.4 /home/andy/Github/captcha-recognition/PyProj/ML/securimage/convolution.py
Initializing neural network with 2 layers, 1936 inputs and 29 outputs.
  - Convl: Rectifier  Output: (42, 42)   Channels: 8
  - Dense: Softmax    Units:  29  

Training on dataset of 3,500 samples with 6,877,500 total size.
  - Reshaping input array from (3500, 1936) to (3150, 1, 44, 44).
  - Train: 3,150      Valid: 350 
  - Using `L2` for regularization.
  - Terminating loop after 100 total iterations.
  - Early termination after 10 stable iterations.

Epoch       Training Error       Validation Error       Time
------------------------------------------------------------
    1          3.295e+01             9.456e+00         14.2s
    2          7.846e+00             6.568e+00         13.9s
    3          5.041e+00             5.476e+00         13.4s
    4          3.726e+00             4.570e+00         13.5s
    5          3.001e+00             4.390e+00         13.4s
    6          2.529e+00             4.080e+00         13.5s
    7          2.155e+00             3.417e+00         13.4s
    8          1.831e+00             3.481e+00         13.5s
    9          1.618e+00             3.414e+00         13.5s
   10          1.403e+00             3.667e+00         13.5s
   11          1.237e+00             3.490e+00         13.4s
   12          1.083e+00             3.078e+00         13.4s
   13          9.389e-01             3.345e+00         14.0s
   14          8.573e-01             3.234e+00         13.9s
   15          7.623e-01             3.040e+00         14.4s
   16          6.518e-01             3.107e+00         13.4s
   17          6.187e-01             3.162e+00         13.4s
   18          5.246e-01             3.030e+00         13.4s
   19          4.835e-01             3.121e+00         13.5s
   20          4.050e-01             3.066e+00         13.7s
   21          3.577e-01             2.953e+00         13.5s
   22          3.291e-01             2.923e+00         13.4s
   23          2.917e-01             2.977e+00         13.5s
   24          2.807e-01             2.880e+00         13.5s
   25          2.444e-01             2.940e+00         13.4s
   26          2.095e-01             3.053e+00         13.4s
   27          1.893e-01             2.846e+00         13.4s
   28          1.596e-01             2.810e+00         13.5s
   29          1.553e-01             2.862e+00         13.4s
   30          1.025e-01             2.831e+00         13.4s
   31          1.028e-01             2.828e+00         13.4s
   32          7.654e-02             2.862e+00         13.4s
   33          5.707e-02             2.887e+00         13.4s
   34          5.346e-02             2.854e+00         13.4s
   35          4.589e-02             2.822e+00         13.4s
   36          4.167e-02             2.771e+00         13.5s
   37          2.998e-02             2.758e+00         13.5s
   38          2.045e-02             2.775e+00         13.4s
   39          1.519e-02             2.764e+00         13.5s
   40          8.599e-03             2.750e+00         13.4s
   41          5.219e-03             2.776e+00         13.5s
   42          3.697e-03             2.771e+00         13.5s
   43          3.063e-03             2.774e+00         13.5s
   44          4.122e-03             2.737e+00         13.5s
   45          1.494e-03             2.769e+00         13.4s
   46          9.410e-04             2.780e+00         13.5s
   47          6.613e-04             2.759e+00         13.5s
   48          4.749e-04             2.766e+00         13.5s
   49          4.327e-04             2.768e+00         13.5s
   50          4.087e-04             2.766e+00         13.4s
   51          3.908e-04             2.767e+00         13.4s
   52          3.769e-04             2.767e+00         13.4s
   53          3.651e-04             2.766e+00         13.5s
   54          3.527e-04             2.765e+00         13.5s

Early termination condition fired at 54 iterations.
Classification report for classifier Classifier(batch_size=1, callback=None, debug=False, dropout_rate=None,
      f_stable=0.001,
      hidden0=<sknn.nn.Convolution `Rectifier`: pool_shape=(1, 1), frozen=False, scale_factor=(1, 1), kernel_shape=(3, 3), channels=8, kernel_stride=(1, 1), border_mode='valid', name='hidden0'>,
      layers=[<sknn.nn.Convolution `Rectifier`: pool_shape=(1, 1), frozen=False, scale_factor=(1, 1), kernel_shape=(3, 3), channels=8, kernel_stride=(1, 1), border_mode='valid', name='hidden0'>, <sknn.nn.Layer `Softmax`: name='output', frozen=False, units=29>],
      learning_momentum=0.9, learning_rate=3e-08, learning_rule='momentum',
      loss_type=None, n_iter=100, n_stable=10,
      output=<sknn.nn.Layer `Softmax`: name='output', frozen=False, units=29>,
      random_state=None, regularize='L2',
      valid_set=(array([[[[  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0],
         ...,
         [  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0]]],


       [[[  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0],
         ...,
         [220, 230, ...,   0,   0],
   ..., ...,  0.,  1.],
       ...,
       [ 0.,  0., ...,  0.,  0.],
       [ 0.,  0., ...,  0.,  0.]])),
      valid_size=0.1, verbose=True, warning=None, weight_decay=0.0005,
      weights=None):
             precision    recall  f1-score   support

          2     0.9400    0.8545    0.8952        55
          3     0.8525    0.9123    0.8814        57
          4     1.0000    0.9592    0.9792        49
          5     0.8667    0.9070    0.8864        43
          6     0.6765    0.8846    0.7667        26
          7     0.8814    0.9630    0.9204        54
          8     0.8065    0.7576    0.7812        33
          9     0.9600    0.9057    0.9320        53
          a     0.9574    0.8824    0.9184        51
          b     0.6667    0.6809    0.6737        47
          c     0.9206    0.9355    0.9280        62
          d     0.9048    0.8636    0.8837        44
          e     0.9375    0.8491    0.8911        53
          f     0.9615    0.8475    0.9009        59
          g     0.9062    0.8529    0.8788        68
          h     0.8621    0.9091    0.8850        55
          k     0.9200    0.8846    0.9020        52
          l     1.0000    0.9412    0.9697        51
          m     0.8462    0.7857    0.8148        56
          n     0.8333    0.8333    0.8333        66
          p     0.8571    0.8780    0.8675        41
          r     0.7955    0.7778    0.7865        45
          s     0.7843    0.8511    0.8163        47
          t     0.9048    0.9048    0.9048        63
          u     0.8305    0.9245    0.8750        53
          v     0.8545    0.8704    0.8624        54
          w     0.9074    0.9423    0.9245        52
          y     0.8966    0.9123    0.9043        57
          z     0.8305    0.9074    0.8673        54

avg / total     0.8807    0.8773    0.8779      1500


Confusion matrix:
[[47  0  0  0  0  1  0  0  0  0  0  1  1  0  1  0  0  0  1  0  0  0  0  0
   0  0  0  0  3]
 [ 1 52  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  2  0
   0  0  0  0  1]
 [ 0  0 47  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  1  0  0]
 [ 0  0  0 39  2  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  1 23  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0 52  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   0  0  0  0  1]
 [ 0  3  0  0  0  0 25  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  3  0
   0  0  0  0  0]
 [ 0  1  0  0  3  0  1 48  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1  0  0  0  0  1  0 45  0  0  0  0  0  0  0  1  0  1  0  0  2  0  0
   0  0  0  0  0]
 [ 0  0  0  2  0  0  2  0  0 32  0  1  0  0  1  1  0  0  0  2  1  2  2  0
   0  1  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  1 58  1  0  0  2  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  1  0  1  0  0  0  1  0  2  1 38  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  1  1  0  0  0  0  0  1  0 45  0  0  0  1  0  0  0  0  0  1  0
   3  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0 50  0  0  0  0  0  0  2  1  1  3
   0  1  0  0  0]
 [ 0  2  0  0  4  0  0  0  0  1  2  1  0  0 58  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 50  0  0  2  1  0  0  0  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1 46  0  1  0  0  0  0  0
   0  2  0  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 48  0  0  0  0  0  1
   0  1  0  0  1]
 [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  0 44  4  0  0  1  0
   1  1  2  0  0]
 [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  4  0  0  1 55  0  1  1  0
   1  0  1  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0 36  2  0  0
   0  0  0  1  0]
 [ 0  0  0  0  0  0  1  0  0  1  0  0  0  0  1  1  1  0  1  1  3 35  0  0
   0  0  0  0  0]
 [ 1  1  0  1  1  0  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0 40  0
   0  0  0  0  0]
 [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57
   0  0  0  1  3]
 [ 0  0  0  0  0  0  0  0  0  2  1  0  0  0  1  0  0  0  0  0  0  0  0  0
  49  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   4 47  1  2  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  1  0  0  0  0
   0  0 49  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1
   0  2  0 52  1]
 [ 1  0  0  0  0  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0 49]]

Process finished with exit code 0


/usr/bin/python3.4 /home/andy/Github/captcha-recognition/PyProj/ML/securimage/convolution.py
Initializing neural network with 2 layers, 1936 inputs and 29 outputs.
  - Convl: Rectifier  Output: (42, 42)   Channels: 8
  - Dense: Softmax    Units:  29  

Training on dataset of 3,500 samples with 6,877,500 total size.
  - Reshaping input array from (3500, 1936) to (3150, 1, 44, 44).
  - Train: 3,150      Valid: 350 
  - Using `dropout` for regularization.
  - Terminating loop after 100 total iterations.
  - Early termination after 10 stable iterations.

Epoch       Training Error       Validation Error       Time
------------------------------------------------------------
    1          1.087e+02             6.739e+01          8.3s
    2          6.561e+01             4.257e+01          8.4s
    3          4.491e+01             2.890e+01          8.3s
    4          3.479e+01             2.178e+01          8.4s
    5          2.809e+01             1.789e+01          8.4s
    6          2.402e+01             1.517e+01          8.4s
    7          2.110e+01             1.358e+01          8.3s
    8          1.854e+01             1.206e+01          8.4s
    9          1.670e+01             1.110e+01          8.4s
   10          1.549e+01             1.030e+01          8.4s
   11          1.514e+01             9.589e+00          8.3s
   12          1.415e+01             9.063e+00          8.4s
   13          1.258e+01             8.673e+00          8.3s
   14          1.184e+01             8.129e+00          8.4s
   15          1.134e+01             7.678e+00          8.4s
   16          1.104e+01             7.487e+00          8.4s
   17          1.039e+01             7.398e+00          8.3s
   18          1.027e+01             7.063e+00          8.4s
   19          9.851e+00             6.910e+00          8.4s
   20          9.069e+00             6.622e+00          8.4s
   21          8.769e+00             6.450e+00          8.3s
   22          8.478e+00             6.288e+00          8.4s
   23          8.311e+00             6.297e+00          8.4s
   24          8.369e+00             6.226e+00          8.4s
   25          7.827e+00             5.877e+00          8.4s
   26          7.880e+00             5.784e+00          8.3s
   27          7.607e+00             5.792e+00          8.4s
   28          7.446e+00             5.812e+00          8.4s
   29          7.229e+00             5.420e+00          8.4s
   30          6.970e+00             5.371e+00          8.3s
   31          7.014e+00             5.330e+00          8.4s
   32          6.826e+00             5.314e+00          8.3s
   33          6.771e+00             5.436e+00          8.4s
   34          6.860e+00             5.254e+00          8.4s
   35          6.163e+00             5.175e+00          8.3s
   36          6.390e+00             5.177e+00          8.4s
   37          6.199e+00             5.021e+00          8.4s
   38          6.140e+00             5.114e+00          8.4s
   39          6.012e+00             4.874e+00          8.4s
   40          6.044e+00             4.970e+00          8.3s
   41          5.551e+00             4.947e+00          8.3s
   42          5.682e+00             4.838e+00          8.3s
   43          5.675e+00             4.893e+00          8.4s
   44          5.376e+00             4.704e+00          8.4s
   45          5.163e+00             4.709e+00          8.3s
   46          5.677e+00             4.824e+00          8.3s
   47          4.971e+00             4.705e+00          8.4s
   48          5.285e+00             4.703e+00          8.4s
   49          5.098e+00             4.495e+00          8.4s
   50          5.145e+00             4.617e+00          8.4s
   51          5.072e+00             4.503e+00          8.4s
   52          4.891e+00             4.484e+00          8.4s
   53          4.840e+00             4.472e+00          8.4s
   54          4.834e+00             4.500e+00          8.4s
   55          4.729e+00             4.469e+00          8.4s
   56          4.585e+00             4.345e+00          8.3s
   57          4.445e+00             4.401e+00          8.4s
   58          4.727e+00             4.304e+00          8.4s
   59          4.674e+00             4.449e+00          8.3s
   60          4.744e+00             4.350e+00          8.3s
   61          4.621e+00             4.305e+00          8.3s
   62          4.253e+00             4.272e+00          8.4s
   63          4.702e+00             4.273e+00          8.3s
   64          4.344e+00             4.239e+00          8.4s
   65          4.517e+00             4.280e+00          8.3s
   66          4.144e+00             4.309e+00          8.3s
   67          4.084e+00             4.288e+00          8.4s
   68          4.101e+00             4.190e+00          8.3s
   69          4.035e+00             4.190e+00          8.4s
   70          4.054e+00             4.190e+00          8.3s
   71          3.609e+00             4.166e+00          8.4s
   72          4.213e+00             4.072e+00          8.3s
   73          4.034e+00             4.059e+00          8.4s
   74          3.881e+00             4.092e+00          8.3s
   75          3.731e+00             4.039e+00          8.4s
   76          3.982e+00             4.034e+00          8.4s
   77          3.621e+00             3.986e+00          8.4s
   78          3.787e+00             4.081e+00          8.4s
   79          3.682e+00             4.066e+00          8.4s
   80          3.894e+00             4.056e+00          8.4s
   81          3.374e+00             3.977e+00          8.4s
   82          3.748e+00             3.925e+00          8.4s
   83          3.623e+00             3.970e+00          8.4s
   84          3.619e+00             3.986e+00          8.4s
   85          3.704e+00             4.001e+00          8.4s
   86          3.642e+00             4.004e+00          8.4s
   87          3.452e+00             3.895e+00          8.4s
   88          3.600e+00             3.921e+00          8.4s
   89          3.455e+00             3.861e+00          8.4s
   90          3.212e+00             3.828e+00          8.4s
   91          3.226e+00             3.791e+00          8.3s
   92          3.397e+00             3.747e+00          8.4s
   93          3.238e+00             3.834e+00          8.3s
   94          3.299e+00             3.900e+00          8.3s
   95          3.045e+00             3.901e+00          8.4s
   96          3.311e+00             3.898e+00          8.4s
   97          3.372e+00             3.919e+00          8.3s
   98          3.099e+00             3.794e+00          8.3s
   99          3.176e+00             3.879e+00          8.3s
  100          3.085e+00             3.800e+00          8.3s

Terminating after specified 100 total iterations.
Classification report for classifier Classifier(batch_size=1, callback=None, debug=False, dropout_rate=0.03,
      f_stable=0.001,
      hidden0=<sknn.nn.Convolution `Rectifier`: pool_shape=(1, 1), frozen=False, border_mode='valid', scale_factor=(1, 1), kernel_stride=(1, 1), name='hidden0', channels=8, kernel_shape=(3, 3)>,
      layers=[<sknn.nn.Convolution `Rectifier`: pool_shape=(1, 1), frozen=False, border_mode='valid', scale_factor=(1, 1), kernel_stride=(1, 1), name='hidden0', channels=8, kernel_shape=(3, 3)>, <sknn.nn.Layer `Softmax`: frozen=False, name='output', units=29>],
      learning_momentum=0.9, learning_rate=3e-08, learning_rule='sgd',
      loss_type=None, n_iter=100, n_stable=10,
      output=<sknn.nn.Layer `Softmax`: frozen=False, name='output', units=29>,
      random_state=None, regularize='dropout',
      valid_set=(array([[[[  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0],
         ...,
         [  0,   0, ...,   0,   0],
         [  0,   0, ...,   0,   0]]],


       [[[  0,  98, ...,   0,   0],
         [142, 185, ...,   0,   0],
         ...,
         [255, 255, ...,   0,   0],
   ..., ...,  0.,  0.],
       ...,
       [ 0.,  0., ...,  0.,  1.],
       [ 0.,  0., ...,  0.,  0.]])),
      valid_size=0.1, verbose=True, warning=None, weight_decay=None,
      weights=None):
             precision    recall  f1-score   support

          2     1.0000    0.8462    0.9167        52
          3     0.9200    0.9200    0.9200        50
          4     0.9811    0.9811    0.9811        53
          5     0.8780    0.7200    0.7912        50
          6     0.7843    0.8511    0.8163        47
          7     0.9615    0.8929    0.9259        56
          8     0.7941    0.6585    0.7200        41
          9     0.7255    0.9024    0.8043        41
          a     0.9800    0.9608    0.9703        51
          b     0.7368    0.7500    0.7434        56
          c     0.9444    0.9808    0.9623        52
          d     0.8889    0.9412    0.9143        51
          e     0.8462    0.8730    0.8594        63
          f     0.9492    0.9655    0.9573        58
          g     0.9400    0.8868    0.9126        53
          h     0.8393    0.9400    0.8868        50
          k     0.9111    0.9111    0.9111        45
          l     0.9559    0.9559    0.9559        68
          m     0.9318    0.7885    0.8542        52
          n     0.8000    0.9412    0.8649        51
          p     0.9796    0.9412    0.9600        51
          r     0.8793    0.8947    0.8870        57
          s     0.7333    0.8302    0.7788        53
          t     0.9231    0.9412    0.9320        51
          u     0.9483    0.9821    0.9649        56
          v     0.9143    0.8205    0.8649        39
          w     0.9773    0.8776    0.9247        49
          y     0.9636    0.9464    0.9550        56
          z     0.9020    0.9583    0.9293        48

avg / total     0.8986    0.8947    0.8947      1500


Confusion matrix:
[[44  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  5]
 [ 0 46  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  1  0  0  0  1  0
   0  0  0  0  0]
 [ 0  0 52  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0
   0  0  0  0  0]
 [ 0  0  0 36  3  0  0  0  0  3  0  0  1  1  1  0  0  0  0  0  0  0  5  0
   0  0  0  0  0]
 [ 0  0  0  2 40  0  0  0  0  1  0  2  0  0  1  0  0  0  0  0  0  0  1  0
   0  0  0  0  0]
 [ 0  1  0  0  0 50  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  3
   0  0  0  0  0]
 [ 0  0  0  0  3  0 27  3  0  2  0  0  0  1  0  0  0  0  0  0  0  1  4  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0 37  0  0  0  0  0  0  1  0  0  0  0  1  1  0  1  0
   0  0  0  0  0]
 [ 0  1  1  0  0  0  0  0 49  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  1  4  0  4  0  0 42  0  1  1  0  0  0  0  0  0  0  0  1  2  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 51  1  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  2  0  1  0 48  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  1  0  0  0  0  1  2  0  0 55  0  0  0  1  1  0  0  0  0  2  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0  0  0  0  0  0  1  0  0
   0  0  0  0  0]
 [ 0  1  0  0  0  0  0  0  0  0  3  0  1  0 47  0  0  0  0  0  0  0  0  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 47  0  0  0  2  0  0  0  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 41  1  0  0  0  1  0  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0 65  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  1  0 41  5  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  1  0  0 48  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0 48  1  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  2  0  0  3  0  0  0  0  0  0  0  0  0  1  0 51  0  0
   0  0  0  0  0]
 [ 0  1  0  1  1  0  1  3  0  1  0  0  1  0  0  0  0  0  0  0  0  0 44  0
   0  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 48
   0  0  0  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0
  55  0  0  0  0]
 [ 0  0  0  0  0  0  0  2  0  0  0  0  2  0  0  0  0  0  0  1  0  0  0  0
   0 32  1  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  2  0  0  0  0
   0  2 43  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1
   0  1  0 53  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0
   0  0  0  0 46]]

Process finished with exit code 0


/usr/bin/python3.4 /home/andy/Github/captcha-recognition/PyProj/ML/securimage/convolution.py
Initializing neural network with 2 layers, 1936 inputs and 29 outputs.
  - Convl: Rectifier  Output: (42, 42)   Channels: 8
  - Dense: Softmax    Units:  29  

Training on dataset of 3,500 samples with 6,877,500 total size.
  - Reshaping input array from (3500, 1936) to (3500, 1, 44, 44).
  - Using `dropout` for regularization.
  - Terminating loop after 100 total iterations.
  - Early termination after 10 stable iterations.

Epoch       Training Error       Validation Error       Time
------------------------------------------------------------
    1          5.343e+01                 N/A            9.0s
    2          3.905e+01                 N/A            9.0s
    3          3.268e+01                 N/A            9.0s
    4          2.918e+01                 N/A            9.0s
    5          2.670e+01                 N/A            9.0s
    6          2.540e+01                 N/A            9.1s
    7          2.418e+01                 N/A            9.0s
    8          2.252e+01                 N/A            9.0s
    9          2.133e+01                 N/A            9.0s
   10          2.056e+01                 N/A            9.0s
   11          1.953e+01                 N/A            9.1s
   12          1.905e+01                 N/A            9.3s
   13          1.803e+01                 N/A            9.0s
   14          1.725e+01                 N/A            9.4s
   15          1.681e+01                 N/A            9.0s
   16          1.583e+01                 N/A            9.0s
   17          1.526e+01                 N/A            9.0s
   18          1.474e+01                 N/A            9.0s
   19          1.434e+01                 N/A            9.0s
   20          1.386e+01                 N/A            9.1s
   21          1.346e+01                 N/A            9.0s
   22          1.303e+01                 N/A            9.0s
   23          1.251e+01                 N/A            9.0s
   24          1.235e+01                 N/A            9.0s
   25          1.169e+01                 N/A            9.0s
   26          1.128e+01                 N/A            9.0s
   27          1.103e+01                 N/A            9.0s
   28          1.068e+01                 N/A            9.0s
   29          1.030e+01                 N/A            9.0s
   30          1.008e+01                 N/A            9.0s
   31          9.611e+00                 N/A            9.0s
   32          9.300e+00                 N/A            9.0s
   33          9.221e+00                 N/A            9.1s
   34          8.753e+00                 N/A            9.0s
   35          8.507e+00                 N/A            9.0s
   36          8.357e+00                 N/A            9.0s
   37          8.123e+00                 N/A            9.0s
   38          8.081e+00                 N/A            9.0s
   39          7.877e+00                 N/A            9.0s
   40          7.556e+00                 N/A            9.0s
   41          7.573e+00                 N/A            9.0s
   42          7.117e+00                 N/A            9.0s
   43          7.086e+00                 N/A            9.0s
   44          7.158e+00                 N/A            9.1s
   45          6.708e+00                 N/A            9.0s
   46          6.423e+00                 N/A            9.1s
   47          6.651e+00                 N/A            9.0s
   48          6.545e+00                 N/A            9.0s
   49          6.460e+00                 N/A            9.0s
   50          6.218e+00                 N/A            9.0s
   51          6.059e+00                 N/A            9.0s
   52          6.153e+00                 N/A            9.0s
   53          5.973e+00                 N/A            9.0s
   54          5.710e+00                 N/A            9.0s
   55          5.733e+00                 N/A            9.0s
   56          5.482e+00                 N/A            9.0s
   57          5.441e+00                 N/A            9.0s
   58          5.444e+00                 N/A            9.0s
   59          5.297e+00                 N/A            9.1s
   60          5.170e+00                 N/A            9.1s
   61          5.143e+00                 N/A            9.0s
   62          4.773e+00                 N/A            9.0s
   63          5.151e+00                 N/A            9.0s
   64          4.810e+00                 N/A            9.1s
   65          4.833e+00                 N/A            9.0s
   66          4.796e+00                 N/A            9.0s
   67          4.731e+00                 N/A            9.0s
   68          4.749e+00                 N/A            9.0s
   69          4.428e+00                 N/A            8.9s
   70          4.480e+00                 N/A            8.9s
   71          4.548e+00                 N/A            8.9s
   72          4.358e+00                 N/A            8.9s
   73          4.235e+00                 N/A            9.0s
   74          4.067e+00                 N/A            8.9s
   75          4.133e+00                 N/A            8.9s
   76          4.163e+00                 N/A            8.9s
   77          4.105e+00                 N/A            9.0s
   78          4.065e+00                 N/A            9.0s
   79          4.135e+00                 N/A            9.0s
   80          3.930e+00                 N/A            9.0s
   81          4.047e+00                 N/A            9.0s
   82          3.790e+00                 N/A            9.0s
   83          3.875e+00                 N/A            9.0s
   84          3.797e+00                 N/A            9.0s
   85          3.706e+00                 N/A            9.0s
   86          3.687e+00                 N/A            9.0s
   87          3.520e+00                 N/A            9.0s
   88          3.701e+00                 N/A            9.0s
   89          3.647e+00                 N/A            9.0s
   90          3.540e+00                 N/A            9.1s
   91          3.496e+00                 N/A            9.0s
   92          3.570e+00                 N/A            9.0s
   93          3.406e+00                 N/A            9.0s
   94          3.589e+00                 N/A            9.0s
   95          3.449e+00                 N/A            9.0s
   96          3.289e+00                 N/A            9.0s
   97          3.381e+00                 N/A            9.0s
   98          3.281e+00                 N/A            9.0s
   99          3.320e+00                 N/A            9.0s
  100          3.197e+00                 N/A            9.0s

Terminating after specified 100 total iterations.
Classification report for classifier Classifier(batch_size=1, callback=None, debug=False, dropout_rate=0.03,
      f_stable=0.001,
      hidden0=<sknn.nn.Convolution `Rectifier`: kernel_shape=(3, 3), channels=8, name='hidden0', frozen=False, scale_factor=(1, 1), pool_shape=(1, 1), border_mode='valid', kernel_stride=(1, 1)>,
      layers=[<sknn.nn.Convolution `Rectifier`: kernel_shape=(3, 3), channels=8, name='hidden0', frozen=False, scale_factor=(1, 1), pool_shape=(1, 1), border_mode='valid', kernel_stride=(1, 1)>, <sknn.nn.Layer `Softmax`: units=29, name='output', frozen=False>],
      learning_momentum=0.9, learning_rate=3e-08, learning_rule='sgd',
      loss_type=None, n_iter=100, n_stable=10,
      output=<sknn.nn.Layer `Softmax`: units=29, name='output', frozen=False>,
      random_state=None, regularize='dropout', valid_set=None,
      valid_size=0.0, verbose=True, warning=None, weight_decay=None,
      weights=None):
             precision    recall  f1-score   support

          2     0.8627    0.9167    0.8889        48
          3     0.8571    0.6818    0.7595        44
          4     0.9259    0.9434    0.9346        53
          5     0.6889    0.7561    0.7209        41
          6     0.7941    0.6923    0.7397        39
          7     0.8824    0.7258    0.7965        62
          8     0.6364    0.5526    0.5915        38
          9     0.7808    0.7917    0.7862        72
          a     0.9348    0.9149    0.9247        47
          b     0.5211    0.6727    0.5873        55
          c     0.7800    0.8298    0.8041        47
          d     0.7258    0.7895    0.7563        57
          e     0.8654    0.8491    0.8571        53
          f     0.9412    0.8889    0.9143        54
          g     0.8302    0.6769    0.7458        65
          h     0.8200    0.7736    0.7961        53
          k     0.8372    0.9474    0.8889        38
          l     1.0000    0.9787    0.9892        47
          m     0.8431    0.7167    0.7748        60
          n     0.7833    0.7966    0.7899        59
          p     0.8537    0.7778    0.8140        45
          r     0.6610    0.8478    0.7429        46
          s     0.6545    0.7500    0.6990        48
          t     0.9020    0.8846    0.8932        52
          u     0.8364    0.9020    0.8679        51
          v     0.9167    0.8049    0.8571        41
          w     0.8462    0.9167    0.8800        60
          y     0.8710    0.9643    0.9153        56
          z     0.9077    0.8551    0.8806        69

avg / total     0.8216    0.8147    0.8153      1500


Confusion matrix:
[[44  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0
   0  0  0  0  1]
 [ 2 30  0  1  0  0  1  2  0  2  0  1  0  0  0  0  0  0  0  0  0  0  4  0
   0  0  0  0  1]
 [ 0  0 50  0  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0 31  2  0  1  1  0  1  0  1  0  0  0  0  0  0  0  0  0  0  4  0
   0  0  0  0  0]
 [ 0  0  1  4 27  0  2  0  0  2  0  0  0  0  1  0  0  0  0  0  0  0  1  0
   1  0  0  0  0]
 [ 0  2  0  0  0 45  0  1  0  1  0  0  0  1  0  0  1  0  0  0  0  0  0  3
   0  2  0  2  4]
 [ 0  0  1  2  0  0 21  1  0  8  0  1  0  0  0  0  0  0  0  0  1  1  2  0
   0  0  0  0  0]
 [ 0  2  0  1  0  0  1 57  0  3  0  1  0  0  0  0  0  0  0  1  0  1  5  0
   0  0  0  0  0]
 [ 0  0  1  0  0  0  0  0 43  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0
   0  0  1  0  0]
 [ 0  0  0  3  1  0  3  0  0 37  0  3  0  0  0  2  0  0  2  0  0  1  2  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 39  4  1  0  3  0  0  0  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  3  4 45  0  0  2  0  0  0  0  0  0  0  0  0
   3  0  0  0  0]
 [ 0  0  0  1  0  0  0  0  0  4  0  0 45  0  2  0  0  0  0  0  0  1  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  1 48  0  0  0  0  0  0  2  0  0  1
   0  0  2  0  0]
 [ 1  0  0  1  1  0  0  6  0  2  6  0  3  0 44  0  0  0  0  0  0  0  0  0
   1  0  0  0  0]
 [ 0  0  0  0  1  0  0  0  0  1  0  0  0  0  0 41  1  0  1  4  0  3  0  0
   1  0  0  0  0]
 [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 36  0  0  0  0  1  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 46  0  0  0  0  0  0
   0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0 43  6  1  3  0  0
   2  0  2  0  0]
 [ 0  0  1  0  0  0  0  0  1  1  0  0  0  0  0  2  2  0  2 47  0  2  0  0
   0  0  1  0  0]
 [ 0  0  0  0  0  0  0  0  0  1  0  2  0  0  0  0  1  0  0  0 35  4  0  0
   0  0  1  1  0]
 [ 0  0  0  0  0  0  1  0  0  2  0  0  0  0  0  3  0  0  0  0  0 39  1  0
   0  0  0  0  0]
 [ 0  0  0  1  1  0  0  1  0  0  1  3  1  0  0  1  0  0  0  0  0  2 36  0
   0  0  1  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0 46
   0  0  1  2  0]
 [ 0  0  0  0  0  0  2  1  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0
  46  0  0  0  0]
 [ 0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0
   0 33  1  3  0]
 [ 1  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0
   0  0 55  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   0  1  0 54  0]
 [ 3  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0
   0  0  0  0 59]]

Process finished with exit code 0
